{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Training a model from ACDC dataset\n",
    "\n",
    "**Authors :**\n",
    "* _Louis Lacroix_\n",
    "* _Benjamin Ternot_"
   ],
   "id": "d85cb06818d795a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## I. Importing Libraries and Global Settings",
   "id": "6eb440fcdd4469a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "import gc\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import psutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "\n",
    "from data_manager.datamanager import DataLoader\n",
    "from models.model import Unet\n",
    "from models.modeltrainer import ModelPreprocessor, DiffusionModelTrainer, Diffusion\n",
    "from utils.utils import VerboseLevel"
   ],
   "id": "5da660255e85029d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Parameters to use for the preprocessing\n",
    "IMAGE_SIZE=64\n",
    "PADDING=0.2\n",
    "IMAGE_NAMES=[\"ED_gt\", \"ES_gt\"]\n",
    "LINK_GT_TO_DATA=False\n",
    "KEEP_3D_CONSISTENCY=False\n",
    "CHANNELS=4\n",
    "RESCALE_OUTPUT_KEY=\"rescaled_image_data\"\n",
    "MAX_ANGLE=45\n",
    "NB_ROTATIONS=7\n",
    "VERBOSE=VerboseLevel.DISPLAY\n",
    "# VerboseLevel.NONE to avoid outputs\n",
    "# VerboseLevel.TQDM to use tqdm progress bars\n",
    "# VerboseLevel.PRINT to print information\n",
    "# VerboseLevel.DISPLAY to display images\n",
    "\n",
    "# Execution parameters\n",
    "LIBERATE_MEMORY=True\n",
    "CUDA_DEVICE = 0\n",
    "\n",
    "# Parameters for the model training\n",
    "SAVE_MODEL = True\n",
    "SAVE_INTERMEDIATE_MODELS = {\"toggle\": False, \"frequency\": 20}\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 100\n",
    "T = 1000\n",
    "DIM_MULTS = (1, 2, 4, 8)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Modifier les couleurs des textes et des axes en fonction du thÃ¨me de Jupyter\n",
    "DARK_BG = False\n",
    "\n",
    "if DARK_BG:\n",
    "    plt.rcParams['text.color'] = 'black'\n",
    "    plt.rcParams['axes.labelcolor'] = 'white'\n",
    "    plt.rcParams['xtick.color'] = 'white'\n",
    "    plt.rcParams['ytick.color'] = 'white'\n",
    "    plt.rcParams['axes.titlecolor'] = 'white'\n",
    "else:\n",
    "    plt.rcParams['text.color'] = 'black'\n",
    "    plt.rcParams['axes.labelcolor'] = 'black'\n",
    "    plt.rcParams['xtick.color'] = 'black'\n",
    "    plt.rcParams['ytick.color'] = 'black'\n",
    "    plt.rcParams['axes.titlecolor'] = 'black'"
   ],
   "id": "712cb98b9c7344e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## II. Data Loading and Preprocessing",
   "id": "35c5d30b979106fa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the root data folder\n",
    "root_data_folder = os.path.join(os.path.dirname(os.getcwd()), 'database')\n",
    "\n",
    "# Define the sub path to the folders containing the data\n",
    "data_sub_folders = {\n",
    "    \"train\": \"training\",\n",
    "    \"test\": \"testing\",\n",
    "}\n",
    "\n",
    "# Define the mapping from group labels to diagnostic classes\n",
    "group_map = {\n",
    "    \"NOR\": \"Healthy control\",\n",
    "    \"MINF\": \"Myocardial infarction\",\n",
    "    \"DCM\": \"Dilated cardiomyopathy\",\n",
    "    \"HCM\": \"Hypertrophic cardiomyopathy\",\n",
    "    \"RV\": \"Abnormal right ventricle\"\n",
    "}"
   ],
   "id": "d3681fd0f7898e25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the data loader\n",
    "data_loader = DataLoader(root_folder=root_data_folder)\n",
    "\n",
    "# Load the data\n",
    "for key, sub_folder in data_sub_folders.items():\n",
    "    data_loader.load_data(sub_folder, name=key, store=True, verbose=VERBOSE)\n",
    "\n",
    "# Create the model trainer\n",
    "model_preprocessor = ModelPreprocessor(data_loader, group_map)"
   ],
   "id": "6d2aaa41e372e1dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preprocess the data\n",
    "preprocessed_data = model_preprocessor.preprocess_data(\n",
    "    target_shape=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    padding=PADDING,\n",
    "    image_names=IMAGE_NAMES,\n",
    "    link_gt_to_data=LINK_GT_TO_DATA,\n",
    "    keep_3d_consistency=KEEP_3D_CONSISTENCY,\n",
    "    create_channels_from_gt=CHANNELS>1,\n",
    "    rescale_output_key=RESCALE_OUTPUT_KEY,\n",
    "    max_angle=MAX_ANGLE,\n",
    "    nb_rotations=NB_ROTATIONS,\n",
    "    verbose=VERBOSE\n",
    ")"
   ],
   "id": "d8f9a2e1b84fda18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Liberate memory if needed\n",
    "def get_memory_usage():\n",
    "    \"\"\"Return the memory usage in MB\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1e6\n",
    "\n",
    "if LIBERATE_MEMORY:\n",
    "    memory_before = get_memory_usage()\n",
    "    del data_loader\n",
    "    del model_preprocessor\n",
    "    gc.collect()\n",
    "    memory_after = get_memory_usage()\n",
    "    if VERBOSE >= VerboseLevel.PRINT:\n",
    "        print(f\"Memory usage before: {memory_before/1000:.4f} GB\"\n",
    "              f\"\\nMemory usage after: {memory_after/1000:.4f} GB\"\n",
    "              f\"\\nMemory liberated: {memory_before - memory_after:.2f} MB\"\n",
    "        )"
   ],
   "id": "1b8c37528cf5dfaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## III. Model Training",
   "id": "3fff972c424839db"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the root data folder\n",
    "ROOT_RES_FOLDER = os.path.join(os.path.dirname(os.getcwd()), 'resources')\n",
    "\n",
    "# Saving paths\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "IMAGES_SAVE_FOLDER = os.path.join(\n",
    "    ROOT_RES_FOLDER,\n",
    "    \"images\",\n",
    "    f\"{current_datetime.strftime('%Y-%m-%d-%H-%M')}_\" + (f'{CHANNELS}-channels_' if CHANNELS>1 else '1-channel'),\n",
    "    \"training\"\n",
    ")\n",
    "IMAGES_SAVE_PATH = os.path.join(IMAGES_SAVE_FOLDER, \"{}\")\n",
    "\n",
    "MODEL_SAVE_FOLDER = os.path.join(\n",
    "    ROOT_RES_FOLDER,\n",
    "    \"trained_models\",\n",
    "    f\"{current_datetime.strftime('%Y-%m-%d-%H-%M')}_\" + (f'{CHANNELS}-channels' if CHANNELS>1 else '1-channel')\n",
    ")\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_FOLDER, \"{}_unet.pt\")\n",
    "PARAMS_SAVE_PATH = os.path.join(MODEL_SAVE_FOLDER, \"params.txt\")\n",
    "\n",
    "# Create folders to save the models\n",
    "os.makedirs(IMAGES_SAVE_FOLDER, exist_ok=True)\n",
    "os.makedirs(MODEL_SAVE_FOLDER, exist_ok=True)"
   ],
   "id": "78a918220892378d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Write parameters to the file\n",
    "SAVE_PARAMS = {\n",
    "    \"IMAGE_SIZE\": IMAGE_SIZE,\n",
    "    \"CHANNELS\": CHANNELS,\n",
    "    \"BATCH_SIZE\": BATCH_SIZE,\n",
    "    \"EPOCHS\": EPOCHS,\n",
    "    \"T\": T,\n",
    "    \"DIM_MULTS\": DIM_MULTS\n",
    "}\n",
    "with open(PARAMS_SAVE_PATH, \"w\") as file:\n",
    "    for key, value in SAVE_PARAMS.items():\n",
    "        file.write(f\"{key} = {value}\\n\")\n",
    "if VERBOSE >= VerboseLevel.PRINT:\n",
    "    print(f\"Parameters saved to '{PARAMS_SAVE_PATH}'\")"
   ],
   "id": "d03e1017ea488c91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "device = torch.device(f\"cuda:{CUDA_DEVICE}\" if torch.cuda.is_available() else \"cpu\")",
   "id": "526b2af86119aa12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the model\n",
    "model = Unet(\n",
    "    dim=IMAGE_SIZE,\n",
    "    init_dim=None,\n",
    "    out_dim=None,\n",
    "    dim_mults=DIM_MULTS,\n",
    "    channels= CHANNELS,\n",
    "    with_time_emb=True,\n",
    "    convnext_mult=2,\n",
    ").to(device)\n",
    "model_trainer = DiffusionModelTrainer(\n",
    "    data_set=preprocessed_data,\n",
    "    val_split=0.1,\n",
    "    model=model,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    criterion=nn.SmoothL1Loss(),\n",
    "    optimizer=Adam(model.parameters(), lr=1e-4),\n",
    "    device=device,\n",
    "    verbose=VERBOSE,\n",
    "    image_filename=IMAGES_SAVE_PATH\n",
    ")"
   ],
   "id": "dc7213ad487c5cc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "constants_scheduler = partial(Diffusion.cosine_beta_schedule, s=0.008)\n",
    "losses_history=model_trainer.train(\n",
    "    epochs=EPOCHS,\n",
    "    timesteps=T,\n",
    "    constants_scheduler=constants_scheduler,\n",
    "    save_model_path=MODEL_SAVE_PATH,\n",
    "    save_images_path=IMAGES_SAVE_PATH,\n",
    "    save_intermediate_models=SAVE_INTERMEDIATE_MODELS,\n",
    "    verbose=VERBOSE\n",
    ")"
   ],
   "id": "fbf3939a7933c0fa",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
